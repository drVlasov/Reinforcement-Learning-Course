{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5vnG3UCxHLq"
      },
      "source": [
        "## On-policy learning and SARSA\n",
        "\n",
        "_This notebook builds upon `qlearning.ipynb`, or to be exact your implementation of QLearningAgent._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSUkU2pTxHLu",
        "outputId": "800b806e-d201-41dc-f673-01520c04bd2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 148492 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXkY7ylfxHLv"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppVaJhWvxHLv"
      },
      "source": [
        "You can copy your `QLearningAgent` implementation from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W8Swl1axHLw"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        value = np.max([self.get_qvalue(state, action) for action in possible_actions])\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        Q_value = (1 - learning_rate) * self.get_qvalue (state, action) + learning_rate * (reward + gamma * self.get_value(next_state))\n",
        "\n",
        "        self.set_qvalue(state, action, Q_value)\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        best_action = np.argmax([self.get_qvalue(state, action) for action in possible_actions])\n",
        "\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.getPolicy).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        if epsilon >= np.random.uniform():\n",
        "          chosen_action = np.random.choice(possible_actions)\n",
        "\n",
        "        else:\n",
        "          chosen_action = self.get_best_action(state)\n",
        "\n",
        "\n",
        "\n",
        "        return chosen_action"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_3r-1yqxHLx"
      },
      "source": [
        "Now we gonna implement Expected Value SARSA on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtLOQgz1xHLx"
      },
      "source": [
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability  (1‚àíùúñ) ,\n",
        "    otherwise samples action at random. Note that agent can occasionally sample optimal action during random sampling by pure chance.\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        ##<YOUR CODE: see docstring>\n",
        "        n_actions = len(possible_actions)\n",
        "        pi = [(1/n_actions) * epsilon for _ in range(n_actions)]\n",
        "        k = self.get_best_action(state)\n",
        "        pi[k] = pi[k] + (1-epsilon)\n",
        "        pi = np.array(pi)\n",
        "        q_values = [self.get_qvalue(state, action) for action in possible_actions]\n",
        "        state_value = np.sum(pi * q_values)\n",
        "\n",
        "\n",
        "        return state_value\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sb4-pt6xHLy"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png width=600>\n",
        "<center><i>image by cs188</i></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTrnYI2lxHLy",
        "outputId": "76310a0a-db3f-4f2f-eaef-cd883b292529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMs-gkXIxHLz",
        "outputId": "4f7bc2ed-52a4-4020-f4d7-47862905a06a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpIa4IQXxHLz"
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiewXqUOxHLz"
      },
      "source": [
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-O63u_HxHL0",
        "outputId": "2e1b09eb-c470-4c46-b7d8-8cf91c93c6d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVSARSA mean reward = -28.43\n",
            "QLEARNING mean reward = -62.34\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhMu2TG9xHL0"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jtq7ROhxHL0"
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbYbt2nhxHL1",
        "outputId": "2707c523-8bfd-4c6d-9835-1f85cb9c41f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Learning\n",
            " >  v  >  v  >  v  v  v  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  ^  ^  ^  ^  ^  ^  ^  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk1K-wf2xHL1"
      },
      "source": [
        "### Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NepUOpDwxHL1",
        "outputId": "43324026-2d13-4843-da47-ca6a0eb6a0c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from submit import submit_sarsa\n",
        "submit_sarsa(rewards_ql, rewards_sarsa, 'vlasovve@inbox.ru', 'ylE1I1ZjJrRyrZto')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitted to Coursera platform. See results on assignment page!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEiRXvjlxHL1"
      },
      "source": [
        "### More\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    }
  ]
}